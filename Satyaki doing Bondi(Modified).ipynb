{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "69b2ebb2-71df-4bdb-9156-b3ca0d19478f",
    "_uuid": "0df9e934921cd91b0358b5752afe56ede37f3e1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test\n",
      "train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "de580565-a3b5-4b0c-b6e3-3fbd4bfd0b78",
    "_uuid": "0fab7b111545360cebd3388b6ac8030a5a1150e8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_paths = []\n",
    "for subdir, dirs, files in os.walk(\"../input\"):\n",
    "    for file in files:\n",
    "        #print os.path.join(subdir, file)\n",
    "        filepath = subdir + os.sep + file\n",
    "        list_paths.append(filepath)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ad2510c7-6cdc-4683-bdda-44de6e7b59e2",
    "_uuid": "cd6a34a8b8ac61560d75d06512e721e53706e67a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_train = [filepath for filepath in list_paths if \"train/\" in filepath]\n",
    "shuffle(list_train)\n",
    "list_test = [filepath for filepath in list_paths if \"test/\" in filepath]\n",
    "\n",
    "list_train = list_train\n",
    "list_test = list_test\n",
    "index = [os.path.basename(filepath) for filepath in list_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "16c8699d-2222-4de0-a297-0f1d9e77445b",
    "_uuid": "d7273fd6ff53762125d5248a243d1012ff3ce9c1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = list(set([os.path.dirname(filepath).split(os.sep)[-1] for filepath in list_paths if \"train\" in filepath]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "850c5764-e009-46ce-9080-96e0f47ffbc6",
    "_uuid": "56ac73fe15195693a58a8171c64dffadadec31f8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = ['Sony-NEX-7',\n",
    " 'Motorola-X',\n",
    " 'HTC-1-M7',\n",
    " 'Samsung-Galaxy-Note3',\n",
    " 'Motorola-Droid-Maxx',\n",
    " 'iPhone-4s',\n",
    " 'iPhone-6',\n",
    " 'LG-Nexus-5x',\n",
    " 'Samsung-Galaxy-S4',\n",
    " 'Motorola-Nexus-6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "abacfb3c-10df-4f19-b032-2b3fb06c48dc",
    "_uuid": "a2a733db5a2250c7daacd3e5bb12794d38c78a8c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_from_path(filepath):\n",
    "    return os.path.dirname(filepath).split(os.sep)[-1]\n",
    "\n",
    "def read_and_resize(filepath):\n",
    "    im_array = np.array(Image.open((filepath)), dtype=\"uint8\")\n",
    "    pil_im = Image.fromarray(im_array)\n",
    "    new_array = np.array(pil_im.resize((256,256)))\n",
    "    return new_array/255\n",
    "\n",
    "def label_transform(labels):\n",
    "    labels = pd.get_dummies(pd.Series(labels))\n",
    "    label_index = labels.columns.values\n",
    "\n",
    "    return labels, label_index\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "2ec89065-7057-4557-8d19-57c61799f904",
    "_kg_hide-output": true,
    "_uuid": "d601bdbd9ee568b31ed0c3ac8a1ccafbabacca7f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array([read_and_resize(filepath) for filepath in list_train])\n",
    "X_test = np.array([read_and_resize(filepath) for filepath in list_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d49ad9f6-aa39-4de4-9e3f-34d7e9a3cd44",
    "_uuid": "37c83c31f7619f00ae1e47d29cdf0b9d2517de7b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [get_class_from_path(filepath) for filepath in list_train]\n",
    "y, label_index = label_transform(labels)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8ffb7b2-4b03-409b-ba7b-1208cb000395",
    "_uuid": "d784c240abe66ef95450913717748778cd0996bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, kernel_size=3, strides=2, input_shape=(256, 256,..., activation=\"relu\", padding=\"valid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 127, 127, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 61, 61, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,725,674\n",
      "Trainable params: 3,725,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1924 samples, validate on 826 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler, EarlyStopping \n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "#from keras.layers import Input \n",
    "#from keras.layers import BatchNormalization, GlobalMaxPool2D, Concatenate\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#input_shape = (256, 256, 3)\n",
    "nclass = len(label_index)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    '''\n",
    "    nclass = len(label_index)\n",
    "    inp = Input(shape=input_shape)\n",
    "    norm_inp = BatchNormalization()(inp)\n",
    "    img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding=\"same\")(norm_inp)\n",
    "    img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "    img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "    img_1 = Convolution2D(64, kernel_size=2, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = Convolution2D(20, kernel_size=2, activation=activations.relu, padding=\"same\")(img_1)\n",
    "    img_1 = GlobalMaxPool2D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "    dense_1 = Dense(20, activation=activations.relu)(img_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, kernel_size=3, strides=2, border_mode= 'valid', input_shape=(256,256,3), activation= 'relu' ))\n",
    "    model.add(Convolution2D(64,kernel_size=3, strides=2 , activation= 'relu' ))\n",
    "    model.add(Convolution2D(32,kernel_size=3, strides=1 , activation= 'relu' ))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    #model.add(Convolution2D(64, 3, 3, activation= 'relu' ))\n",
    "    #model.add(Convolution2D(32, 3, 3, activation= 'relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten()) \n",
    "    #model.add(Dense(228, activation= 'relu' ))\n",
    "    model.add(Dense(128, activation= 'relu' ))  \n",
    "    model.add(Dense(nclass, activation= 'softmax' )) \n",
    "    model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "model = get_model()\n",
    "model.summary()\n",
    "\n",
    "file_path=\"weights.best.hdf5\"\n",
    "# check will store the best model weight which will monitor the validation accuracy not train accuracy\n",
    "check  = ModelCheckpoint(file_path, monitor = 'val_acc', verbose=1, save_best_only=True, mode='max' )\n",
    "#early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=1)\n",
    "\n",
    "checkpoints = [check]\n",
    "\n",
    "#model.fit(x, y_train, validation_split = 0.3,epochs=25, batch_size=30,verbose=2, callbacks = checkpoints)\n",
    "history = model.fit(X_train, y, validation_split=0.3, epochs=10, shuffle=True,batch_size=30, verbose=2,\n",
    "                              callbacks=checkpoints)\n",
    "\n",
    "'''\n",
    "model = get_model()\n",
    "file_path=\"weights.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=1)\n",
    "\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "\n",
    "history = model.fit(X_train, y, validation_split=0.1, epochs=3, shuffle=True, verbose=2,\n",
    "                              callbacks=callbacks_list)\n",
    "'''\n",
    "\n",
    "#print(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c61441e5-fbd3-4aba-a90a-e0083b92a944",
    "_uuid": "412a548f87be342504eb28d8eed716935ec5c346",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(file_path)\n",
    "\n",
    "predicts = model.predict(X_test)\n",
    "predicts = np.argmax(predicts, axis=1)\n",
    "predicts = [label_index[p] for p in predicts]\n",
    "\n",
    "df = pd.DataFrame(columns=['fname', 'camera'])\n",
    "df['fname'] = index\n",
    "df['camera'] = predicts\n",
    "df.to_csv(\"sub.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9cf251c3-23ed-41e0-b9f5-2ac90314db43",
    "_uuid": "343f1896b5f68a697b40f9b8f289f5fcadf38312",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
